{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install torcheval\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","!pip install gdown"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T10:37:10.790467Z","iopub.status.busy":"2023-06-25T10:37:10.790076Z","iopub.status.idle":"2023-06-25T10:37:22.834381Z","shell.execute_reply":"2023-06-25T10:37:22.833427Z","shell.execute_reply.started":"2023-06-25T10:37:10.790428Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import sys\n","import math\n","import gdown\n","import torch\n","import random\n","import tensorflow as tf\n","import torch.nn.functional as F\n","import cv2 as cv\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch import nn, optim, Tensor\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from collections import OrderedDict\n","from skimage import io, transform\n","from sklearn.model_selection import train_test_split\n","# from torchmetrics.functional import dice_score"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T10:37:22.836507Z","iopub.status.busy":"2023-06-25T10:37:22.835676Z","iopub.status.idle":"2023-06-25T10:37:22.871393Z","shell.execute_reply":"2023-06-25T10:37:22.870511Z","shell.execute_reply.started":"2023-06-25T10:37:22.836468Z"},"trusted":true},"outputs":[],"source":["gc.enable()\n","\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T10:37:22.874995Z","iopub.status.busy":"2023-06-25T10:37:22.874605Z","iopub.status.idle":"2023-06-25T10:37:30.067597Z","shell.execute_reply":"2023-06-25T10:37:30.066720Z","shell.execute_reply.started":"2023-06-25T10:37:22.874958Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From (uriginal): https://drive.google.com/uc?id=1gm6x4PXw9pTS2EdxuT7ZabEH1gMWcUCU\n","From (redirected): https://drive.google.com/uc?id=1gm6x4PXw9pTS2EdxuT7ZabEH1gMWcUCU&confirm=t&uuid=ae7b4a19-b070-4828-9d44-1f36e3e4abed\n","To: /kaggle/working/best.model.pth\n","100%|██████████| 195M/195M [00:00<00:00, 200MB/s] \n","Downloading...\n","From (uriginal): https://drive.google.com/uc?id=1SSKZiCwaI6PC2ffNvPn1OTDN6MJ7lI1X\n","From (redirected): https://drive.google.com/uc?id=1SSKZiCwaI6PC2ffNvPn1OTDN6MJ7lI1X&confirm=t&uuid=5b80eb08-1662-4981-91e0-b45e7d63c1d8\n","To: /kaggle/working/best_unet_model.pth\n","100%|██████████| 275M/275M [00:04<00:00, 61.2MB/s] \n"]},{"data":{"text/plain":["'best_unet_model.pth'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#CONST\n","TRAIN = '/kaggle/input/airbus-ship-detection/train_v2/'\n","TEST = '/kaggle/input/airbus-ship-detection/test_v2/'\n","LOGS = '/kaggle/working/'\n","LABELS = '/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv'\n","ORIG_IMG_SIZE = 768\n","IMG_SIZE = 224\n","BATCH_SIZE = 128 #128\n","LEARNING_RATE = 0.001\n","EPOCH = 1\n","URL_RESNET = \"https://drive.google.com/uc?id=1gm6x4PXw9pTS2EdxuT7ZabEH1gMWcUCU\"\n","URL_UNET = \"https://drive.google.com/uc?id=1SSKZiCwaI6PC2ffNvPn1OTDN6MJ7lI1X\"\n","\n","# corrupted image\n","exclude_list = ['6384c3e78.jpg', '13703f040.jpg', '14715c06d.jpg', '33e0ff2d5.jpg',\n","                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg',\n","                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n","                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg']\n","\n","#download pretrained model for encoder\n","gdown.download(url=URL_RESNET, output=\"best.model.pth\", quiet=False)\n","gdown.download(url=URL_UNET, output=\"best_unet_model.pth\", quiet=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T10:37:30.074168Z","iopub.status.busy":"2023-06-25T10:37:30.071634Z","iopub.status.idle":"2023-06-25T10:37:44.787706Z","shell.execute_reply":"2023-06-25T10:37:44.784901Z","shell.execute_reply.started":"2023-06-25T10:37:30.074112Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["found non empty 42556\n"]}],"source":["all_names = [f for f in os.listdir(TRAIN)]\n","test_names = [f for f in os.listdir(TEST)]\n","\n","for el in exclude_list:\n","    if el in all_names:\n","        all_names.remove(el)\n","    if el in test_names:\n","        test_names.remove(el)\n","\n","train_names, val_names = train_test_split(all_names, test_size=0.05, random_state=42)\n","\n","segmentation_df = pd.read_csv(LABELS).set_index('ImageId')\n","num_negative_ex = 150000\n","num_positive_ex = 42556\n","positive_ratio = num_positive_ex/(num_positive_ex+num_negative_ex)\n","negative_ratio = num_negative_ex/(num_positive_ex+num_negative_ex)\n","\n","def cut_empty(names):\n","    return [name for name in names if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]\n","\n","non_empty_names = cut_empty(all_names)\n","print('found non empty', len(non_empty_names))\n","\n","nonempty_train_names, nonempty_val_names = train_test_split(non_empty_names, test_size=0.05, random_state=42)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T10:37:44.792762Z","iopub.status.busy":"2023-06-25T10:37:44.792394Z","iopub.status.idle":"2023-06-25T10:37:46.027400Z","shell.execute_reply":"2023-06-25T10:37:46.026431Z","shell.execute_reply.started":"2023-06-25T10:37:44.792726Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n","100%|██████████| 83.3M/83.3M [00:00<00:00, 254MB/s]\n"]}],"source":["def get_mask(img_id, df):\n","    ''' get binary mask from run length encoding'''\n","    shape = (ORIG_IMG_SIZE, ORIG_IMG_SIZE)\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    masks = df.loc[img_id]['EncodedPixels']\n","    if type(masks) == float:\n","        return img.reshape(shape)\n","    if type(masks) == str:\n","        masks = [masks]\n","    for mask in masks:\n","        s = mask.split()\n","        for i in range(len(s)//2):\n","            start = int(s[2*i]) - 1\n","            length = int(s[2*i+1])\n","            img[start:start+length] = 1\n","    return img.reshape(shape).T\n","\n","\n","class ships_mask_dataset(Dataset):\n","    ''' dataset consisting of images and masks'''\n","    def __init__(self, names, transform=None):\n","        self.names = names\n","        self.transform = transform\n","\n","    def __getitem__(self, id):\n","        name = self.names[id]\n","        image = cv.imread(os.path.join(TRAIN, name))\n","        mask = get_mask(name, segmentation_df)\n","        if self.transform:\n","            transformed = self.transform(image, mask)\n","            image, mask = transformed['image'], transformed['mask'].float()\n","        return {'id': name, 'image': image, 'mask': mask}\n","\n","    def __len__(self):\n","        return len(self.names)\n","\n","\n","class test_image_dataset(Dataset):\n","    ''' dataset consisting of images'''\n","    def __init__(self, names):\n","        self.names = names\n","\n","    def __getitem__(self, id):\n","        name = self.names[id]\n","        img = cv.imread(os.path.join(TEST, name))\n","        img = cv.resize(img, (IMG_SIZE, IMG_SIZE))\n","        img = transforms.ToTensor()(img)\n","        return{'id': name, 'image': img}\n","\n","    def __len__(self):\n","        return len(self.names)\n","\n","\n","class ships_detect_dataset(Dataset):\n","    ''' dataset consisting of images and classes'''\n","    def __init__(self, names, transform=None):\n","        self.names = names\n","        self.transform = transform\n","\n","    def __getitem__(self, id):\n","        name = self.names[id]\n","        img = cv.imread(os.path.join(TRAIN, name))\n","        if type(segmentation_df.loc[name]['EncodedPixels']) == float:\n","            cl = 0\n","        else:\n","            cl = 1  # class 0 no ship class 1 ship\n","        if self.transform:\n","            img = self.transform(img)\n","            cltens = torch.tensor(cl)\n","        return{'id': name, 'image': img, 'class': cltens}\n","\n","    def __len__(self):\n","        return len(self.names)\n","\n","\n","class transform(object):\n","    '''transformation with image and mask augmentation'''\n","    def __call__(self, image, mask):\n","        image = cv.resize(image, (IMG_SIZE, IMG_SIZE))\n","        mask = cv.resize(mask, (IMG_SIZE, IMG_SIZE))\n","        r = random.choice([1, 0, -1])\n","        image = cv.flip(image, r)\n","        mask = cv.flip(mask, r)\n","        image = transforms.ToPILImage()(image)\n","        image = transforms.ColorJitter(\n","            brightness=0.1, contrast=0.1, saturation=0.1)(image)\n","        image = transforms.ToTensor()(image)\n","        mask = torch.from_numpy(mask)\n","        return {'image': image, 'mask': mask}\n","\n","\n","class transform_img(object):\n","    '''transformation with image augmentation'''\n","    def __call__(self, image):\n","        image = cv.resize(image, (IMG_SIZE, IMG_SIZE))\n","        r = random.choice([1, 0, -1])\n","        image = cv.flip(image, r)\n","        image = transforms.ToPILImage()(image)\n","        image = transforms.ColorJitter(\n","            brightness=0.1, contrast=0.1, saturation=0.1)(image)\n","        image = transforms.ToTensor()(image)\n","        return image\n","\n","\n","class transform_no_aug(object):\n","    ''' resize and convert to tensor'''\n","    def __call__(self, image, mask):\n","        image = cv.resize(image, (IMG_SIZE, IMG_SIZE))\n","        mask = cv.resize(mask, (IMG_SIZE, IMG_SIZE))\n","        image = transforms.ToTensor()(image)\n","        mask = torch.from_numpy(mask)\n","        return {'image': image, 'mask': mask}\n","\n","\n","tr = transform_img()\n","detect_train_set = ships_detect_dataset(train_names, tr)\n","detect_val_set = ships_detect_dataset(val_names, tr)\n","\n","mask_tr = transform()\n","mask_tr_no_aug = transform_no_aug()\n","\n","mask_train_set = ships_mask_dataset(nonempty_train_names, mask_tr)\n","# mask_val_set = ships_mask_dataset(nonempty_val_names, mask_tr)\n","mask_val_set = ships_mask_dataset(nonempty_val_names, mask_tr)\n","mask_val_no_aug_set = ships_mask_dataset(nonempty_val_names, mask_tr_no_aug)\n","\n","\n","resnet = models.resnet34(pretrained=True)\n","#resnet = models.resnet34(weights=ResNet34_Weights.DEFAULT)#or weights=ResNet34_Weights.IMAGENET1K_V1\n","\n","def resnet_feature_dim(size):\n","    ''' computes dimension of resnet feature output layer'''\n","    assert size >= 224, 'image size must be >=224'\n","    x = torch.from_numpy(np.zeros((1, 3, size, size))).float()\n","    x = resnet.conv1(x)\n","    x = resnet.bn1(x)\n","    x = resnet.relu(x)\n","    x = resnet.maxpool(x)\n","    x = resnet.layer1(x)\n","    x = resnet.layer2(x)\n","    x = resnet.layer3(x)\n","    x = resnet.layer4(x)\n","    x = resnet.avgpool(x)\n","    x = x.view(x.size(0), -1)\n","    return x.shape[1]\n","\n","\n","resnet_out_features = resnet_feature_dim(IMG_SIZE)\n","\n","\n","class myresnet(nn.Module):\n","    '''resnet model that outputs intermeddiate features'''\n","    def __init__(self, hidden_layers):\n","        super(myresnet, self).__init__()\n","        self.backbone = resnet\n","        self.classifier = nn.Sequential(OrderedDict([\n","            ('fc1', nn.Linear(resnet_out_features, hidden_layers)),\n","            ('relu', nn.ReLU()),\n","            ('fc2', nn.Linear(hidden_layers, 2)),\n","            ('output', nn.LogSoftmax(dim=1))\n","        ]))\n","\n","    def forward(self, x):\n","        x = self.backbone.conv1(x)\n","        x = self.backbone.bn1(x)\n","        x = self.backbone.relu(x)\n","        l0 = self.backbone.maxpool(x)\n","        l1 = self.backbone.layer1(l0)\n","        l2 = self.backbone.layer2(l1)\n","        l3 = self.backbone.layer3(l2)\n","        l4 = self.backbone.layer4(l3)\n","        out = self.backbone.avgpool(l4)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return {'layer0': l0, 'layer1': l1, 'layer2': l2,\n","                'layer3': l3, 'layer4': l4, 'class': out}\n","\n","\n","def detection_train(epochs):\n","    ''' trains resnet for detection'''\n","    rn = myresnet(512)\n","    wght = torch.Tensor([positive_ratio, negative_ratio])\n","    wght = wght.to(device)\n","    dloss = nn.NLLLoss(weight=wght)\n","\n","    lrs = [rn.backbone.conv1, rn.backbone.bn1, rn.backbone.maxpool,\n","           rn.backbone.layer1, rn.backbone.layer2, rn.backbone.layer3]\n","    for l in lrs:\n","        for x in l.parameters():\n","            x.requires_grad = False\n","    active_parameters = [par for par in rn.parameters() if par.requires_grad == True]\n","    print('training active pars:', len(active_parameters))\n","    optimizer = optim.Adam(active_parameters, lr=LEARNING_RATE)\n","\n","    train_loader = DataLoader(detect_train_set, batch_size=BATCH_SIZE)\n","    val_loader = DataLoader(detect_val_set, batch_size=BATCH_SIZE)\n","\n","    rn.to(device)\n","    current_epoch = 0\n","    best_val_loss = None\n","    train_loss = []\n","    val_loss = []\n","    val_accuracy = []\n","    MODEL_PATH = os.path.join(LOGS, 'best.model.pth')\n","    if os.path.isfile(MODEL_PATH):\n","        if torch.cuda.is_available():\n","            checkpoint = torch.load(MODEL_PATH)\n","        else:\n","            checkpoint = torch.load(MODEL_PATH, map_location='cpu')\n","        current_epoch = checkpoint['epoch']\n","        best_val_loss = checkpoint['loss']\n","        train_loss = checkpoint['train_loss']\n","        val_loss = checkpoint['val_loss']\n","        if 'val_accuracy' in checkpoint.keys():\n","            val_accuracy = checkpoint['val_accuracy']\n","        print('loading model from', MODEL_PATH)\n","        rn.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    print('start training')\n","    for epoch in range(current_epoch, epochs):\n","        print('epoch', epoch)\n","        running_loss = 0\n","        num_batches = 0\n","        rn.train()\n","        trlen = len(train_loader)\n","        for sample in train_loader:\n","            image, cls = sample['image'], sample['class']\n","            image, cls = image.to(device), cls.to(device)\n","            optimizer.zero_grad()\n","            predict = rn(image)['class']\n","            loss = dloss(predict, cls)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            print(str(num_batches)+'/'+str(trlen)+' batch loss', loss.item())\n","            num_batches += 1\n","        print('epoch ', epoch, ', train loss:', running_loss/num_batches)\n","        train_loss.append(running_loss/num_batches)\n","        running_loss = 0\n","        num_batches = 0\n","        num_examples = 0\n","        TP = 0\n","        PREDICTED = 0\n","        REALPOSITIVE = 0\n","        CORRECT = 0\n","        rn.eval()\n","        for sample in val_loader:\n","            image, cls = sample['image'], sample['class']\n","            image, cls = image.to(device), cls.to(device)\n","            predict = rn(image)['class']\n","            loss = dloss(predict, cls)\n","            running_loss += loss.item()\n","            num_batches += 1\n","            num_examples += cls.size(0)\n","            predict = torch.max(predict, 1)[1]\n","            CORRECT += (predict == cls).sum().item()\n","            TP += (predict*cls).sum().item()\n","            PREDICTED += predict.sum().item()\n","            REALPOSITIVE += cls.sum().item()\n","        valloss = running_loss/num_batches\n","        try:\n","            precision = TP/(PREDICTED)\n","            recall = TP/(REALPOSITIVE)\n","        except:\n","            precision = 1\n","            recall = 1\n","        print('num_examples', num_examples)\n","        print('epoch ', epoch, ', val loss:', valloss, 'val accuracy', CORRECT /\n","              num_examples, 'val f1 score', 2*precision*recall/(precision+recall))\n","\n","        val_loss.append(valloss)\n","        val_accuracy.append(CORRECT/num_examples)\n","        if not best_val_loss:\n","            best_val_loss = valloss\n","            torch.save({'loss': valloss,\n","                        'epoch': epoch,\n","                        'model_state_dict': rn.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict(),\n","                        'train_loss': train_loss,\n","                        'val_loss': val_loss,\n","                        'val_accuracy': val_accuracy},\n","                       MODEL_PATH)\n","        elif valloss < best_val_loss:\n","            best_val_loss = valloss\n","            torch.save({'loss': valloss,\n","                        'epoch': epoch,\n","                        'model_state_dict': rn.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict(),\n","                        'train_loss': train_loss,\n","                        'val_loss': val_loss,\n","                        'val_accuracy': val_accuracy},\n","                       MODEL_PATH)\n","    return {'model': rn, 'val_loss': val_loss, 'val_accuracy': val_accuracy}\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, rene):\n","        super(UNet, self).__init__()\n","        self.rene = rene\n","        self.ct2d = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n","        self.c2d = nn.Conv2d(512, 256, kernel_size=3, padding=1, stride=1)\n","        self.bn1 = nn.BatchNorm2d(256)\n","        self.relu = nn.ReLU()\n","        self.ct2d2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n","        self.c2d2 = nn.Conv2d(256, 128, kernel_size=3, padding=1, stride=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.ct2d3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.c2d3 = nn.Conv2d(128, 64, kernel_size=3, padding=1, stride=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.ct2d4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.c2d4 = nn.Conv2d(64, 32, kernel_size=3, padding=1, stride=1)\n","        self.bn4 = nn.BatchNorm2d(32)\n","        self.ct2d5 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n","        self.c2d5 = nn.Conv2d(16, 1, kernel_size=1, stride=1)\n","\n","    def forward(self, x):\n","        g = self.rene(x)\n","        l0 = g['layer0']\n","        l1 = g['layer1']\n","        l2 = g['layer2']\n","        l3 = g['layer3']\n","        l4 = g['layer4']\n","        out = g['class']\n","        up = self.ct2d(l4)  # increase size from IMG_SIZE/32 to IMG_SIZE/16\n","        up = torch.cat([l3, up], dim=1)  # size Nx512xIMG/SIZE/16**2\n","        up = self.c2d(up)  # size Nx256xIMG_SIZE/16**2\n","        up = self.bn1(up)\n","        up = self.relu(up)\n","        up = self.ct2d2(up)  # size Nx128xIMG_SIZE/8**2\n","        up = torch.cat([l2, up], dim=1)  # size Nx256xIMG_SIZE/8**2\n","        up = self.c2d2(up)  # size Nx128xIMG_SIZE/8**2\n","        up = self.bn2(up)\n","        up = self.relu(up)\n","        up = self.ct2d3(up)  # size Nx64xIMG_SIZE/4**2\n","        up = torch.cat([l1, up], dim=1)  # size Nx128xIMG_SIZE/4**2\n","        up = self.c2d3(up)  # size Nx64xIMG_SIZE/4**2\n","        up = self.bn3(up)\n","        up = self.relu(up)\n","        up = torch.cat([l0, up], dim=1)  # size Nx128xIMG_SIZE/4**2\n","        up = self.ct2d4(up)  # size Nx64xIMG_SIZE/2**2\n","        up = self.c2d4(up)  # size Nx16xIMG_SIZE/2**2\n","        up = self.bn4(up)\n","        up = self.relu(up)\n","        up = self.ct2d5(up)  # size Nx8xIMG_SIZE**2\n","        up = self.c2d5(up)\n","        up = torch.squeeze(up)\n","        up = nn.LogSigmoid()(up)\n","        return up\n","\n","\n","class IoULoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, input, target):\n","        N, H, W = input.shape\n","        p = input.exp()\n","        intersection = (p*target).sum(1).sum(1)\n","        union = (p+target).sum(1).sum(1)-intersection\n","        iou = intersection/(union+1)\n","        assert iou.shape == torch.Size([N]), 'iouloss shape failure'\n","        loss = 1-iou\n","        return loss.mean()\n","\n","\n","class CELoss(nn.Module):\n","    def __init__(self, alpha):\n","        super().__init__()\n","        self.alpha = alpha\n","\n","    def forward(self, input, target):\n","        N, H, W = input.shape\n","        p = input.exp()\n","        alphat = self.alpha*target+(1-self.alpha)*(1-target)\n","        pt = p*target+(1-p)*(1-target)\n","        loss = -alphat*(pt.log())\n","        loss = loss.sum(1).sum(1)\n","        assert loss.shape == torch.Size([N]), 'loss shape failure'\n","        return loss.mean()\n","\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma):\n","        super().__init__()\n","        self.gamma = gamma\n","\n","    def forward(self, input, target):\n","        if not (target.size() == input.size()):\n","            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n","                             .format(target.size(), input.size()))\n","\n","        max_val = (-input).clamp(min=0)\n","        loss = input - input * target + max_val + \\\n","            ((-max_val).exp() + (-input - max_val).exp()).log()\n","\n","        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n","        loss = (invprobs * self.gamma).exp() * loss\n","\n","        return loss.mean()\n","\n","\n","class MixLoss(nn.Module):\n","    def __init__(self, gamma):\n","        super().__init__()\n","        self.iou = IoULoss()\n","        self.floss = FocalLoss(gamma)\n","\n","    def forward(self, input, target):\n","        return self.iou(input, target)+0.1*self.floss(input, target)\n","\n","\n","def IoU(input, target):\n","    N, H, W = input.shape\n","    input = (input.exp() > 0.5).float()\n","    intersection = (input*target).sum(1).sum(1)\n","    assert intersection.shape == torch.Size([N]), 'IoU shape failure'\n","    return ((intersection) / ((input+target).sum(1).sum(1) - intersection + 1.0)).sum()/N\n","\n","def DICE(input, target):\n","    N, H, W = input.shape\n","    input = (input.exp() > 0.5).float()\n","    return (2.0 * (input*target).sum(1).sum(1) / ((input+target).sum(1).sum(1) + 1.0)).sum()/N\n","\n","train_mask_loader = DataLoader(mask_train_set, batch_size=BATCH_SIZE)\n","val_mask_loader = DataLoader(mask_val_set, batch_size=BATCH_SIZE)\n","\n","\n","class Tensorboard:\n","    def __init__(self, logdir):\n","        self.writer = tf.summary.create_file_writer(logdir)\n","        \n","\n","    def close(self):\n","        self.writer.close()\n","\n","    def log_scalar(self, tag, value, global_step):\n","        with self.writer.as_default():\n","             for _ in range(global_step):\n","                tf.summary.scalar(tag, value, step=_)\n","                self.writer.flush()\n","\n","\n","def unet_train(rn, epochs):\n","    '''trains U-Net for mask detection'''\n","    un = UNet(rn)\n","    un = un.to(device)\n","    maskloss = MixLoss(gamma=0.69314)\n","    for x in un.parameters():\n","        x.requires_grad = True\n","    lrs = [un.rene.backbone.conv1, un.rene.backbone.bn1,\n","           un.rene.backbone.maxpool, un.rene.backbone.layer1, un.rene.backbone.layer2]\n","    for l in lrs:\n","        for x in l.parameters():\n","            x.requires_grad = False\n","    active_parameters = [x for x in un.parameters() if x.requires_grad == True]\n","    optimizer = optim.Adam(active_parameters, lr=LEARNING_RATE)\n","    print('UNet training ', len(active_parameters), ' active parameters')\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5,\n","                                  verbose=True, threshold=0.00001, threshold_mode='rel',\n","                                  cooldown=0, min_lr=0, eps=1e-08)\n","\n","    current_epoch = 0\n","    best_val_iou = None\n","    MODEL_PATH = os.path.join(LOGS, 'best_unet_model.pth')\n","    if os.path.isfile(MODEL_PATH):\n","        if torch.cuda.is_available():\n","            checkpoint = torch.load(MODEL_PATH)\n","        else:\n","            checkpoint = torch.load(MODEL_PATH, map_location='cpu')\n","        current_epoch = checkpoint['epoch']\n","        if 'best_val_iou' in checkpoint.keys():\n","            best_val_iou = checkpoint['best_val_iou']\n","        print('loading model from', MODEL_PATH)\n","        un.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    val_iou = best_val_iou\n","    print('start training UNet')\n","    tensorboard = Tensorboard('tblogs')\n","    for epoch in range(current_epoch, epochs):\n","        torch.cuda.empty_cache()\n","        print('epoch', epoch)\n","        running_loss = 0\n","        num_batches = 0\n","        un.train()\n","        trlen = len(train_mask_loader)\n","        for sample in train_mask_loader:\n","            image, mask = sample['image'], sample['mask']\n","            image, mask = image.to(device), mask.to(device)\n","            optimizer.zero_grad()\n","            predict = un(image)\n","            loss = maskloss(predict, mask)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            iou = IoU(predict, mask)\n","            print(str(num_batches)+'/'+str(trlen)+' batch loss',\n","                  loss.item(), 'batch avg IoU', iou)\n","            num_batches += 1\n","        print('epoch ', epoch, 'num batches', num_batches,\n","              ' train loss:', running_loss/num_batches)\n","        tensorboard.log_scalar('train_loss', running_loss/num_batches, epoch)\n","        running_loss = 0\n","        num_batches = 0\n","        iou = 0\n","        un.eval()\n","        for sample in val_mask_loader:\n","            image, mask = sample['image'], sample['mask']\n","            image, mask = image.to(device), mask.to(device)\n","            predict = un(image)\n","            mask = torch.squeeze(mask)\n","            loss = maskloss(predict, mask)\n","            running_loss += loss.item()\n","            iou += IoU(predict, mask)\n","            num_batches += 1\n","        valiou = iou/num_batches\n","        valloss = running_loss/num_batches\n","        scheduler.step(valloss)\n","        print('epoch ', epoch, 'validation IoU', valiou)\n","        tensorboard.log_scalar('val_loss', valloss, epoch)\n","        tensorboard.log_scalar('validation IoU', valiou, epoch)\n","        val_iou = valiou\n","        if not best_val_iou:\n","            best_val_iou = val_iou\n","            torch.save({'epoch': epoch,\n","                        'model_state_dict': un.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict(),\n","                        'best_val_iou': val_iou},\n","                       MODEL_PATH)\n","        elif val_iou > best_val_iou:\n","            best_val_iou = val_iou\n","            torch.save({'epoch': epoch,\n","                        'model_state_dict': un.state_dict(),\n","                        'optimizer_state_dict': optimizer.state_dict(),\n","                        'best_val_iou': val_iou},\n","                       MODEL_PATH)\n","    return {'model': un, 'val_iou': val_iou}"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T10:37:46.029178Z","iopub.status.busy":"2023-06-25T10:37:46.028835Z","iopub.status.idle":"2023-06-25T10:37:51.075911Z","shell.execute_reply":"2023-06-25T10:37:51.074745Z","shell.execute_reply.started":"2023-06-25T10:37:46.029129Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training active pars: 27\n","loading model from /kaggle/working/best.model.pth\n","start training\n","Loaded ResNet\n"]}],"source":["g = detection_train(0)\n","rn, valloss, accuracy = g['model'], g['val_loss'], g['val_accuracy']\n","print('Loaded ResNet')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T11:14:59.450331Z","iopub.status.busy":"2023-06-25T11:14:59.449917Z","iopub.status.idle":"2023-06-25T11:14:59.840257Z","shell.execute_reply":"2023-06-25T11:14:59.839330Z","shell.execute_reply.started":"2023-06-25T11:14:59.450298Z"},"trusted":true},"outputs":[{"data":{"text/plain":["21"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T11:15:03.436012Z","iopub.status.busy":"2023-06-25T11:15:03.435116Z","iopub.status.idle":"2023-06-25T11:26:47.344704Z","shell.execute_reply":"2023-06-25T11:26:47.343712Z","shell.execute_reply.started":"2023-06-25T11:15:03.435965Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["UNet training  94  active parameters\n","loading model from /kaggle/working/best_unet_model.pth\n","start training UNet\n","epoch 0\n","0/316 batch loss 0.3778833746910095 batch avg IoU tensor(0.6272, device='cuda:0')\n","1/316 batch loss 0.3968200981616974 batch avg IoU tensor(0.6071, device='cuda:0')\n","2/316 batch loss 0.4335165023803711 batch avg IoU tensor(0.5706, device='cuda:0')\n","3/316 batch loss 0.44162845611572266 batch avg IoU tensor(0.5609, device='cuda:0')\n","4/316 batch loss 0.43001794815063477 batch avg IoU tensor(0.5718, device='cuda:0')\n","5/316 batch loss 0.40511634945869446 batch avg IoU tensor(0.5990, device='cuda:0')\n","6/316 batch loss 0.40781140327453613 batch avg IoU tensor(0.5969, device='cuda:0')\n","7/316 batch loss 0.3898910582065582 batch avg IoU tensor(0.6133, device='cuda:0')\n","8/316 batch loss 0.44838380813598633 batch avg IoU tensor(0.5556, device='cuda:0')\n","9/316 batch loss 0.41152215003967285 batch avg IoU tensor(0.5901, device='cuda:0')\n","10/316 batch loss 0.45939764380455017 batch avg IoU tensor(0.5438, device='cuda:0')\n","11/316 batch loss 0.437476247549057 batch avg IoU tensor(0.5667, device='cuda:0')\n","12/316 batch loss 0.4223974347114563 batch avg IoU tensor(0.5826, device='cuda:0')\n","13/316 batch loss 0.4526822566986084 batch avg IoU tensor(0.5486, device='cuda:0')\n","14/316 batch loss 0.4787299931049347 batch avg IoU tensor(0.5227, device='cuda:0')\n","15/316 batch loss 0.42139771580696106 batch avg IoU tensor(0.5822, device='cuda:0')\n","16/316 batch loss 0.41745713353157043 batch avg IoU tensor(0.5845, device='cuda:0')\n","17/316 batch loss 0.4077727794647217 batch avg IoU tensor(0.5948, device='cuda:0')\n","18/316 batch loss 0.40680694580078125 batch avg IoU tensor(0.5966, device='cuda:0')\n","19/316 batch loss 0.43850716948509216 batch avg IoU tensor(0.5651, device='cuda:0')\n","20/316 batch loss 0.4342864453792572 batch avg IoU tensor(0.5699, device='cuda:0')\n","21/316 batch loss 0.4618946313858032 batch avg IoU tensor(0.5405, device='cuda:0')\n","22/316 batch loss 0.41692960262298584 batch avg IoU tensor(0.5891, device='cuda:0')\n","23/316 batch loss 0.4115348756313324 batch avg IoU tensor(0.5920, device='cuda:0')\n","24/316 batch loss 0.409018874168396 batch avg IoU tensor(0.5966, device='cuda:0')\n","25/316 batch loss 0.4207504689693451 batch avg IoU tensor(0.5840, device='cuda:0')\n","26/316 batch loss 0.427379846572876 batch avg IoU tensor(0.5761, device='cuda:0')\n","27/316 batch loss 0.4585714638233185 batch avg IoU tensor(0.5446, device='cuda:0')\n","28/316 batch loss 0.41940563917160034 batch avg IoU tensor(0.5854, device='cuda:0')\n","29/316 batch loss 0.465882807970047 batch avg IoU tensor(0.5383, device='cuda:0')\n","30/316 batch loss 0.4389649033546448 batch avg IoU tensor(0.5638, device='cuda:0')\n","31/316 batch loss 0.3982528746128082 batch avg IoU tensor(0.6051, device='cuda:0')\n","32/316 batch loss 0.41302794218063354 batch avg IoU tensor(0.5907, device='cuda:0')\n","33/316 batch loss 0.44781675934791565 batch avg IoU tensor(0.5544, device='cuda:0')\n","34/316 batch loss 0.4027150273323059 batch avg IoU tensor(0.6010, device='cuda:0')\n","35/316 batch loss 0.434274822473526 batch avg IoU tensor(0.5678, device='cuda:0')\n","36/316 batch loss 0.4153437912464142 batch avg IoU tensor(0.5868, device='cuda:0')\n","37/316 batch loss 0.42593565583229065 batch avg IoU tensor(0.5751, device='cuda:0')\n","38/316 batch loss 0.4819689691066742 batch avg IoU tensor(0.5227, device='cuda:0')\n","39/316 batch loss 0.44949978590011597 batch avg IoU tensor(0.5524, device='cuda:0')\n","40/316 batch loss 0.43052756786346436 batch avg IoU tensor(0.5732, device='cuda:0')\n","41/316 batch loss 0.4226124882698059 batch avg IoU tensor(0.5816, device='cuda:0')\n","42/316 batch loss 0.4313325881958008 batch avg IoU tensor(0.5729, device='cuda:0')\n","43/316 batch loss 0.4407038390636444 batch avg IoU tensor(0.5632, device='cuda:0')\n","44/316 batch loss 0.4227924942970276 batch avg IoU tensor(0.5809, device='cuda:0')\n","45/316 batch loss 0.432186484336853 batch avg IoU tensor(0.5735, device='cuda:0')\n","46/316 batch loss 0.44817447662353516 batch avg IoU tensor(0.5553, device='cuda:0')\n","47/316 batch loss 0.47780492901802063 batch avg IoU tensor(0.5240, device='cuda:0')\n","48/316 batch loss 0.44381946325302124 batch avg IoU tensor(0.5597, device='cuda:0')\n","49/316 batch loss 0.4468139111995697 batch avg IoU tensor(0.5563, device='cuda:0')\n","50/316 batch loss 0.45236727595329285 batch avg IoU tensor(0.5485, device='cuda:0')\n","51/316 batch loss 0.43008148670196533 batch avg IoU tensor(0.5739, device='cuda:0')\n","52/316 batch loss 0.4739161729812622 batch avg IoU tensor(0.5297, device='cuda:0')\n","53/316 batch loss 0.45727652311325073 batch avg IoU tensor(0.5463, device='cuda:0')\n","54/316 batch loss 0.4271602928638458 batch avg IoU tensor(0.5763, device='cuda:0')\n","55/316 batch loss 0.43170151114463806 batch avg IoU tensor(0.5728, device='cuda:0')\n","56/316 batch loss 0.45563071966171265 batch avg IoU tensor(0.5467, device='cuda:0')\n","57/316 batch loss 0.412055104970932 batch avg IoU tensor(0.5924, device='cuda:0')\n","58/316 batch loss 0.4627041220664978 batch avg IoU tensor(0.5397, device='cuda:0')\n","59/316 batch loss 0.4634413719177246 batch avg IoU tensor(0.5395, device='cuda:0')\n","60/316 batch loss 0.49852728843688965 batch avg IoU tensor(0.5034, device='cuda:0')\n","61/316 batch loss 0.454597532749176 batch avg IoU tensor(0.5488, device='cuda:0')\n","62/316 batch loss 0.43952077627182007 batch avg IoU tensor(0.5627, device='cuda:0')\n","63/316 batch loss 0.3946879506111145 batch avg IoU tensor(0.6109, device='cuda:0')\n","64/316 batch loss 0.4206366539001465 batch avg IoU tensor(0.5827, device='cuda:0')\n","65/316 batch loss 0.39255598187446594 batch avg IoU tensor(0.6120, device='cuda:0')\n","66/316 batch loss 0.42219167947769165 batch avg IoU tensor(0.5804, device='cuda:0')\n","67/316 batch loss 0.4453282356262207 batch avg IoU tensor(0.5583, device='cuda:0')\n","68/316 batch loss 0.4621722400188446 batch avg IoU tensor(0.5422, device='cuda:0')\n","69/316 batch loss 0.40354135632514954 batch avg IoU tensor(0.6021, device='cuda:0')\n","70/316 batch loss 0.44604891538619995 batch avg IoU tensor(0.5554, device='cuda:0')\n","71/316 batch loss 0.44761526584625244 batch avg IoU tensor(0.5568, device='cuda:0')\n","72/316 batch loss 0.41937175393104553 batch avg IoU tensor(0.5827, device='cuda:0')\n","73/316 batch loss 0.41349896788597107 batch avg IoU tensor(0.5898, device='cuda:0')\n","74/316 batch loss 0.4230611026287079 batch avg IoU tensor(0.5810, device='cuda:0')\n","75/316 batch loss 0.47305914759635925 batch avg IoU tensor(0.5278, device='cuda:0')\n","76/316 batch loss 0.40375587344169617 batch avg IoU tensor(0.5995, device='cuda:0')\n","77/316 batch loss 0.4465002119541168 batch avg IoU tensor(0.5579, device='cuda:0')\n","78/316 batch loss 0.4377021789550781 batch avg IoU tensor(0.5650, device='cuda:0')\n","79/316 batch loss 0.4166485369205475 batch avg IoU tensor(0.5873, device='cuda:0')\n","80/316 batch loss 0.42779967188835144 batch avg IoU tensor(0.5764, device='cuda:0')\n","81/316 batch loss 0.46494537591934204 batch avg IoU tensor(0.5371, device='cuda:0')\n","82/316 batch loss 0.4574313759803772 batch avg IoU tensor(0.5467, device='cuda:0')\n","83/316 batch loss 0.45543184876441956 batch avg IoU tensor(0.5484, device='cuda:0')\n","84/316 batch loss 0.4178326427936554 batch avg IoU tensor(0.5867, device='cuda:0')\n","85/316 batch loss 0.4480710029602051 batch avg IoU tensor(0.5578, device='cuda:0')\n","86/316 batch loss 0.380619078874588 batch avg IoU tensor(0.6232, device='cuda:0')\n","87/316 batch loss 0.4114792048931122 batch avg IoU tensor(0.5947, device='cuda:0')\n","88/316 batch loss 0.4452466666698456 batch avg IoU tensor(0.5596, device='cuda:0')\n","89/316 batch loss 0.4533780813217163 batch avg IoU tensor(0.5501, device='cuda:0')\n","90/316 batch loss 0.42747727036476135 batch avg IoU tensor(0.5762, device='cuda:0')\n","91/316 batch loss 0.43207502365112305 batch avg IoU tensor(0.5714, device='cuda:0')\n","92/316 batch loss 0.44061341881752014 batch avg IoU tensor(0.5635, device='cuda:0')\n","93/316 batch loss 0.43753325939178467 batch avg IoU tensor(0.5693, device='cuda:0')\n","94/316 batch loss 0.4568461775779724 batch avg IoU tensor(0.5467, device='cuda:0')\n","95/316 batch loss 0.4048326313495636 batch avg IoU tensor(0.5975, device='cuda:0')\n","96/316 batch loss 0.4558110237121582 batch avg IoU tensor(0.5459, device='cuda:0')\n","97/316 batch loss 0.4443569481372833 batch avg IoU tensor(0.5583, device='cuda:0')\n","98/316 batch loss 0.44387346506118774 batch avg IoU tensor(0.5610, device='cuda:0')\n","99/316 batch loss 0.4409744441509247 batch avg IoU tensor(0.5628, device='cuda:0')\n","100/316 batch loss 0.473227322101593 batch avg IoU tensor(0.5304, device='cuda:0')\n","101/316 batch loss 0.4471389353275299 batch avg IoU tensor(0.5559, device='cuda:0')\n","102/316 batch loss 0.39711475372314453 batch avg IoU tensor(0.6066, device='cuda:0')\n","103/316 batch loss 0.41131940484046936 batch avg IoU tensor(0.5914, device='cuda:0')\n","104/316 batch loss 0.43279480934143066 batch avg IoU tensor(0.5709, device='cuda:0')\n","105/316 batch loss 0.42145320773124695 batch avg IoU tensor(0.5816, device='cuda:0')\n","106/316 batch loss 0.4400860071182251 batch avg IoU tensor(0.5621, device='cuda:0')\n","107/316 batch loss 0.4688170552253723 batch avg IoU tensor(0.5336, device='cuda:0')\n","108/316 batch loss 0.4101777672767639 batch avg IoU tensor(0.5930, device='cuda:0')\n","109/316 batch loss 0.39599961042404175 batch avg IoU tensor(0.6077, device='cuda:0')\n","110/316 batch loss 0.48686403036117554 batch avg IoU tensor(0.5164, device='cuda:0')\n","111/316 batch loss 0.4167678654193878 batch avg IoU tensor(0.5871, device='cuda:0')\n","112/316 batch loss 0.44236233830451965 batch avg IoU tensor(0.5596, device='cuda:0')\n","113/316 batch loss 0.48158180713653564 batch avg IoU tensor(0.5209, device='cuda:0')\n","114/316 batch loss 0.3874340057373047 batch avg IoU tensor(0.6164, device='cuda:0')\n","115/316 batch loss 0.4411861002445221 batch avg IoU tensor(0.5591, device='cuda:0')\n","116/316 batch loss 0.3973298668861389 batch avg IoU tensor(0.6048, device='cuda:0')\n","117/316 batch loss 0.49415573477745056 batch avg IoU tensor(0.5112, device='cuda:0')\n","118/316 batch loss 0.45871350169181824 batch avg IoU tensor(0.5461, device='cuda:0')\n","119/316 batch loss 0.42224687337875366 batch avg IoU tensor(0.5820, device='cuda:0')\n","120/316 batch loss 0.40723738074302673 batch avg IoU tensor(0.5959, device='cuda:0')\n","121/316 batch loss 0.42717429995536804 batch avg IoU tensor(0.5741, device='cuda:0')\n","122/316 batch loss 0.41854405403137207 batch avg IoU tensor(0.5840, device='cuda:0')\n","123/316 batch loss 0.4410410523414612 batch avg IoU tensor(0.5611, device='cuda:0')\n","124/316 batch loss 0.4282377362251282 batch avg IoU tensor(0.5747, device='cuda:0')\n","125/316 batch loss 0.4426881968975067 batch avg IoU tensor(0.5603, device='cuda:0')\n","126/316 batch loss 0.4412742257118225 batch avg IoU tensor(0.5608, device='cuda:0')\n","127/316 batch loss 0.436895489692688 batch avg IoU tensor(0.5663, device='cuda:0')\n","128/316 batch loss 0.42265206575393677 batch avg IoU tensor(0.5798, device='cuda:0')\n","129/316 batch loss 0.42474421858787537 batch avg IoU tensor(0.5792, device='cuda:0')\n","130/316 batch loss 0.4471430480480194 batch avg IoU tensor(0.5560, device='cuda:0')\n","131/316 batch loss 0.4053223729133606 batch avg IoU tensor(0.5976, device='cuda:0')\n","132/316 batch loss 0.4436507523059845 batch avg IoU tensor(0.5599, device='cuda:0')\n","133/316 batch loss 0.4118874967098236 batch avg IoU tensor(0.5942, device='cuda:0')\n","134/316 batch loss 0.4320179224014282 batch avg IoU tensor(0.5697, device='cuda:0')\n","135/316 batch loss 0.4800465703010559 batch avg IoU tensor(0.5233, device='cuda:0')\n","136/316 batch loss 0.4004717171192169 batch avg IoU tensor(0.6036, device='cuda:0')\n","137/316 batch loss 0.412002295255661 batch avg IoU tensor(0.5910, device='cuda:0')\n","138/316 batch loss 0.43202540278434753 batch avg IoU tensor(0.5733, device='cuda:0')\n","139/316 batch loss 0.43166694045066833 batch avg IoU tensor(0.5704, device='cuda:0')\n","140/316 batch loss 0.4302709102630615 batch avg IoU tensor(0.5759, device='cuda:0')\n","141/316 batch loss 0.45304369926452637 batch avg IoU tensor(0.5490, device='cuda:0')\n","142/316 batch loss 0.47323766350746155 batch avg IoU tensor(0.5288, device='cuda:0')\n","143/316 batch loss 0.40390482544898987 batch avg IoU tensor(0.5998, device='cuda:0')\n","144/316 batch loss 0.44826987385749817 batch avg IoU tensor(0.5554, device='cuda:0')\n","145/316 batch loss 0.42488157749176025 batch avg IoU tensor(0.5780, device='cuda:0')\n","146/316 batch loss 0.3707744777202606 batch avg IoU tensor(0.6329, device='cuda:0')\n","147/316 batch loss 0.41540437936782837 batch avg IoU tensor(0.5849, device='cuda:0')\n","148/316 batch loss 0.46020397543907166 batch avg IoU tensor(0.5417, device='cuda:0')\n","149/316 batch loss 0.4117080867290497 batch avg IoU tensor(0.5923, device='cuda:0')\n","150/316 batch loss 0.45212629437446594 batch avg IoU tensor(0.5514, device='cuda:0')\n","151/316 batch loss 0.3854285776615143 batch avg IoU tensor(0.6181, device='cuda:0')\n","152/316 batch loss 0.42253684997558594 batch avg IoU tensor(0.5791, device='cuda:0')\n","153/316 batch loss 0.4084186553955078 batch avg IoU tensor(0.5947, device='cuda:0')\n","154/316 batch loss 0.42941179871559143 batch avg IoU tensor(0.5734, device='cuda:0')\n","155/316 batch loss 0.40567538142204285 batch avg IoU tensor(0.5976, device='cuda:0')\n","156/316 batch loss 0.4461595416069031 batch avg IoU tensor(0.5576, device='cuda:0')\n","157/316 batch loss 0.45619282126426697 batch avg IoU tensor(0.5479, device='cuda:0')\n","158/316 batch loss 0.40607139468193054 batch avg IoU tensor(0.5965, device='cuda:0')\n","159/316 batch loss 0.38531190156936646 batch avg IoU tensor(0.6162, device='cuda:0')\n","160/316 batch loss 0.4231623709201813 batch avg IoU tensor(0.5793, device='cuda:0')\n","161/316 batch loss 0.39044907689094543 batch avg IoU tensor(0.6141, device='cuda:0')\n","162/316 batch loss 0.41009122133255005 batch avg IoU tensor(0.5922, device='cuda:0')\n","163/316 batch loss 0.4441407322883606 batch avg IoU tensor(0.5588, device='cuda:0')\n","164/316 batch loss 0.4483215808868408 batch avg IoU tensor(0.5546, device='cuda:0')\n","165/316 batch loss 0.4473780691623688 batch avg IoU tensor(0.5553, device='cuda:0')\n","166/316 batch loss 0.410317063331604 batch avg IoU tensor(0.5952, device='cuda:0')\n","167/316 batch loss 0.4185650944709778 batch avg IoU tensor(0.5845, device='cuda:0')\n","168/316 batch loss 0.4411664605140686 batch avg IoU tensor(0.5624, device='cuda:0')\n","169/316 batch loss 0.41258421540260315 batch avg IoU tensor(0.5906, device='cuda:0')\n","170/316 batch loss 0.422793984413147 batch avg IoU tensor(0.5793, device='cuda:0')\n","171/316 batch loss 0.4456067383289337 batch avg IoU tensor(0.5576, device='cuda:0')\n","172/316 batch loss 0.3997361660003662 batch avg IoU tensor(0.6037, device='cuda:0')\n","173/316 batch loss 0.4235455095767975 batch avg IoU tensor(0.5788, device='cuda:0')\n","174/316 batch loss 0.4636068046092987 batch avg IoU tensor(0.5403, device='cuda:0')\n","175/316 batch loss 0.40937116742134094 batch avg IoU tensor(0.5928, device='cuda:0')\n","176/316 batch loss 0.4457269608974457 batch avg IoU tensor(0.5564, device='cuda:0')\n","177/316 batch loss 0.47057753801345825 batch avg IoU tensor(0.5319, device='cuda:0')\n","178/316 batch loss 0.4141849875450134 batch avg IoU tensor(0.5887, device='cuda:0')\n","179/316 batch loss 0.3843555152416229 batch avg IoU tensor(0.6197, device='cuda:0')\n","180/316 batch loss 0.4294693171977997 batch avg IoU tensor(0.5730, device='cuda:0')\n","181/316 batch loss 0.420804888010025 batch avg IoU tensor(0.5840, device='cuda:0')\n","182/316 batch loss 0.42050138115882874 batch avg IoU tensor(0.5822, device='cuda:0')\n","183/316 batch loss 0.42095160484313965 batch avg IoU tensor(0.5809, device='cuda:0')\n","184/316 batch loss 0.42687755823135376 batch avg IoU tensor(0.5752, device='cuda:0')\n","185/316 batch loss 0.4557856023311615 batch avg IoU tensor(0.5475, device='cuda:0')\n","186/316 batch loss 0.42793697118759155 batch avg IoU tensor(0.5759, device='cuda:0')\n","187/316 batch loss 0.4251352846622467 batch avg IoU tensor(0.5775, device='cuda:0')\n","188/316 batch loss 0.4206036329269409 batch avg IoU tensor(0.5837, device='cuda:0')\n","189/316 batch loss 0.3823840618133545 batch avg IoU tensor(0.6209, device='cuda:0')\n","190/316 batch loss 0.44837379455566406 batch avg IoU tensor(0.5534, device='cuda:0')\n","191/316 batch loss 0.4424605369567871 batch avg IoU tensor(0.5602, device='cuda:0')\n","192/316 batch loss 0.4248198866844177 batch avg IoU tensor(0.5794, device='cuda:0')\n","193/316 batch loss 0.40082430839538574 batch avg IoU tensor(0.6030, device='cuda:0')\n","194/316 batch loss 0.45081090927124023 batch avg IoU tensor(0.5530, device='cuda:0')\n","195/316 batch loss 0.4191893935203552 batch avg IoU tensor(0.5830, device='cuda:0')\n","196/316 batch loss 0.457594096660614 batch avg IoU tensor(0.5445, device='cuda:0')\n","197/316 batch loss 0.4404257535934448 batch avg IoU tensor(0.5630, device='cuda:0')\n","198/316 batch loss 0.42323511838912964 batch avg IoU tensor(0.5793, device='cuda:0')\n","199/316 batch loss 0.4420538544654846 batch avg IoU tensor(0.5602, device='cuda:0')\n","200/316 batch loss 0.45817720890045166 batch avg IoU tensor(0.5452, device='cuda:0')\n","201/316 batch loss 0.4129112660884857 batch avg IoU tensor(0.5890, device='cuda:0')\n","202/316 batch loss 0.4486740231513977 batch avg IoU tensor(0.5550, device='cuda:0')\n","203/316 batch loss 0.4611909091472626 batch avg IoU tensor(0.5409, device='cuda:0')\n","204/316 batch loss 0.43047764897346497 batch avg IoU tensor(0.5758, device='cuda:0')\n","205/316 batch loss 0.38524332642555237 batch avg IoU tensor(0.6176, device='cuda:0')\n","206/316 batch loss 0.47269636392593384 batch avg IoU tensor(0.5298, device='cuda:0')\n","207/316 batch loss 0.4143804907798767 batch avg IoU tensor(0.5899, device='cuda:0')\n","208/316 batch loss 0.4479595422744751 batch avg IoU tensor(0.5556, device='cuda:0')\n","209/316 batch loss 0.4552174210548401 batch avg IoU tensor(0.5475, device='cuda:0')\n","210/316 batch loss 0.45423203706741333 batch avg IoU tensor(0.5476, device='cuda:0')\n","211/316 batch loss 0.41955330967903137 batch avg IoU tensor(0.5833, device='cuda:0')\n","212/316 batch loss 0.417568176984787 batch avg IoU tensor(0.5868, device='cuda:0')\n","213/316 batch loss 0.4528442323207855 batch avg IoU tensor(0.5517, device='cuda:0')\n","214/316 batch loss 0.44368037581443787 batch avg IoU tensor(0.5593, device='cuda:0')\n","215/316 batch loss 0.44198888540267944 batch avg IoU tensor(0.5621, device='cuda:0')\n","216/316 batch loss 0.3846154808998108 batch avg IoU tensor(0.6175, device='cuda:0')\n","217/316 batch loss 0.4920990765094757 batch avg IoU tensor(0.5103, device='cuda:0')\n","218/316 batch loss 0.4326079487800598 batch avg IoU tensor(0.5699, device='cuda:0')\n","219/316 batch loss 0.4489409029483795 batch avg IoU tensor(0.5574, device='cuda:0')\n","220/316 batch loss 0.40272656083106995 batch avg IoU tensor(0.5997, device='cuda:0')\n","221/316 batch loss 0.42779597640037537 batch avg IoU tensor(0.5757, device='cuda:0')\n","222/316 batch loss 0.3998611569404602 batch avg IoU tensor(0.6053, device='cuda:0')\n","223/316 batch loss 0.38580551743507385 batch avg IoU tensor(0.6165, device='cuda:0')\n","224/316 batch loss 0.4154728949069977 batch avg IoU tensor(0.5884, device='cuda:0')\n","225/316 batch loss 0.39277365803718567 batch avg IoU tensor(0.6104, device='cuda:0')\n","226/316 batch loss 0.44801899790763855 batch avg IoU tensor(0.5552, device='cuda:0')\n","227/316 batch loss 0.42759284377098083 batch avg IoU tensor(0.5748, device='cuda:0')\n","228/316 batch loss 0.41546007990837097 batch avg IoU tensor(0.5880, device='cuda:0')\n","229/316 batch loss 0.43428996205329895 batch avg IoU tensor(0.5709, device='cuda:0')\n","230/316 batch loss 0.39437511563301086 batch avg IoU tensor(0.6098, device='cuda:0')\n","231/316 batch loss 0.4285442531108856 batch avg IoU tensor(0.5752, device='cuda:0')\n","232/316 batch loss 0.4332532584667206 batch avg IoU tensor(0.5720, device='cuda:0')\n","233/316 batch loss 0.4153895080089569 batch avg IoU tensor(0.5881, device='cuda:0')\n","234/316 batch loss 0.45873913168907166 batch avg IoU tensor(0.5414, device='cuda:0')\n","235/316 batch loss 0.40765613317489624 batch avg IoU tensor(0.5943, device='cuda:0')\n","236/316 batch loss 0.46302005648612976 batch avg IoU tensor(0.5380, device='cuda:0')\n","237/316 batch loss 0.42535656690597534 batch avg IoU tensor(0.5786, device='cuda:0')\n","238/316 batch loss 0.45238375663757324 batch avg IoU tensor(0.5511, device='cuda:0')\n","239/316 batch loss 0.4190933108329773 batch avg IoU tensor(0.5843, device='cuda:0')\n","240/316 batch loss 0.44569694995880127 batch avg IoU tensor(0.5577, device='cuda:0')\n","241/316 batch loss 0.42253512144088745 batch avg IoU tensor(0.5802, device='cuda:0')\n","242/316 batch loss 0.41469383239746094 batch avg IoU tensor(0.5900, device='cuda:0')\n","243/316 batch loss 0.3988756239414215 batch avg IoU tensor(0.6065, device='cuda:0')\n","244/316 batch loss 0.4437655508518219 batch avg IoU tensor(0.5592, device='cuda:0')\n","245/316 batch loss 0.4248744547367096 batch avg IoU tensor(0.5792, device='cuda:0')\n","246/316 batch loss 0.3888239860534668 batch avg IoU tensor(0.6148, device='cuda:0')\n","247/316 batch loss 0.41367921233177185 batch avg IoU tensor(0.5905, device='cuda:0')\n","248/316 batch loss 0.44791096448898315 batch avg IoU tensor(0.5541, device='cuda:0')\n","249/316 batch loss 0.38538774847984314 batch avg IoU tensor(0.6173, device='cuda:0')\n","250/316 batch loss 0.38198745250701904 batch avg IoU tensor(0.6209, device='cuda:0')\n","251/316 batch loss 0.4545105993747711 batch avg IoU tensor(0.5477, device='cuda:0')\n","252/316 batch loss 0.43632087111473083 batch avg IoU tensor(0.5655, device='cuda:0')\n","253/316 batch loss 0.430475652217865 batch avg IoU tensor(0.5743, device='cuda:0')\n","254/316 batch loss 0.44899338483810425 batch avg IoU tensor(0.5546, device='cuda:0')\n","255/316 batch loss 0.41187140345573425 batch avg IoU tensor(0.5899, device='cuda:0')\n","256/316 batch loss 0.4313724637031555 batch avg IoU tensor(0.5697, device='cuda:0')\n","257/316 batch loss 0.436578631401062 batch avg IoU tensor(0.5693, device='cuda:0')\n","258/316 batch loss 0.41222530603408813 batch avg IoU tensor(0.5921, device='cuda:0')\n","259/316 batch loss 0.42468926310539246 batch avg IoU tensor(0.5814, device='cuda:0')\n","260/316 batch loss 0.46238136291503906 batch avg IoU tensor(0.5403, device='cuda:0')\n","261/316 batch loss 0.3849974274635315 batch avg IoU tensor(0.6191, device='cuda:0')\n","262/316 batch loss 0.38940754532814026 batch avg IoU tensor(0.6142, device='cuda:0')\n","263/316 batch loss 0.41588670015335083 batch avg IoU tensor(0.5871, device='cuda:0')\n","264/316 batch loss 0.42096155881881714 batch avg IoU tensor(0.5814, device='cuda:0')\n","265/316 batch loss 0.4202519655227661 batch avg IoU tensor(0.5824, device='cuda:0')\n","266/316 batch loss 0.42738133668899536 batch avg IoU tensor(0.5768, device='cuda:0')\n","267/316 batch loss 0.37899675965309143 batch avg IoU tensor(0.6260, device='cuda:0')\n","268/316 batch loss 0.4048265814781189 batch avg IoU tensor(0.5987, device='cuda:0')\n","269/316 batch loss 0.4063939154148102 batch avg IoU tensor(0.5970, device='cuda:0')\n","270/316 batch loss 0.43099352717399597 batch avg IoU tensor(0.5718, device='cuda:0')\n","271/316 batch loss 0.40422481298446655 batch avg IoU tensor(0.5986, device='cuda:0')\n","272/316 batch loss 0.40175527334213257 batch avg IoU tensor(0.6002, device='cuda:0')\n","273/316 batch loss 0.441450297832489 batch avg IoU tensor(0.5610, device='cuda:0')\n","274/316 batch loss 0.44849327206611633 batch avg IoU tensor(0.5548, device='cuda:0')\n","275/316 batch loss 0.43176889419555664 batch avg IoU tensor(0.5710, device='cuda:0')\n","276/316 batch loss 0.4178311228752136 batch avg IoU tensor(0.5861, device='cuda:0')\n","277/316 batch loss 0.44373619556427 batch avg IoU tensor(0.5605, device='cuda:0')\n","278/316 batch loss 0.41007867455482483 batch avg IoU tensor(0.5931, device='cuda:0')\n","279/316 batch loss 0.4274823069572449 batch avg IoU tensor(0.5745, device='cuda:0')\n","280/316 batch loss 0.4286600649356842 batch avg IoU tensor(0.5751, device='cuda:0')\n","281/316 batch loss 0.45222267508506775 batch avg IoU tensor(0.5518, device='cuda:0')\n","282/316 batch loss 0.46646225452423096 batch avg IoU tensor(0.5373, device='cuda:0')\n","283/316 batch loss 0.43754979968070984 batch avg IoU tensor(0.5643, device='cuda:0')\n","284/316 batch loss 0.40893229842185974 batch avg IoU tensor(0.5939, device='cuda:0')\n","285/316 batch loss 0.40487566590309143 batch avg IoU tensor(0.5975, device='cuda:0')\n","286/316 batch loss 0.40386566519737244 batch avg IoU tensor(0.5982, device='cuda:0')\n","287/316 batch loss 0.41861966252326965 batch avg IoU tensor(0.5836, device='cuda:0')\n","288/316 batch loss 0.41319969296455383 batch avg IoU tensor(0.5888, device='cuda:0')\n","289/316 batch loss 0.4374612271785736 batch avg IoU tensor(0.5672, device='cuda:0')\n","290/316 batch loss 0.45615988969802856 batch avg IoU tensor(0.5473, device='cuda:0')\n","291/316 batch loss 0.4348982870578766 batch avg IoU tensor(0.5680, device='cuda:0')\n","292/316 batch loss 0.4411041736602783 batch avg IoU tensor(0.5628, device='cuda:0')\n","293/316 batch loss 0.4186488091945648 batch avg IoU tensor(0.5851, device='cuda:0')\n","294/316 batch loss 0.44240614771842957 batch avg IoU tensor(0.5586, device='cuda:0')\n","295/316 batch loss 0.43385690450668335 batch avg IoU tensor(0.5705, device='cuda:0')\n","296/316 batch loss 0.4444800019264221 batch avg IoU tensor(0.5591, device='cuda:0')\n","297/316 batch loss 0.4062769114971161 batch avg IoU tensor(0.5976, device='cuda:0')\n","298/316 batch loss 0.4363913834095001 batch avg IoU tensor(0.5664, device='cuda:0')\n","299/316 batch loss 0.44674527645111084 batch avg IoU tensor(0.5577, device='cuda:0')\n","300/316 batch loss 0.44822657108306885 batch avg IoU tensor(0.5543, device='cuda:0')\n","301/316 batch loss 0.4378242492675781 batch avg IoU tensor(0.5655, device='cuda:0')\n","302/316 batch loss 0.41020870208740234 batch avg IoU tensor(0.5929, device='cuda:0')\n","303/316 batch loss 0.4518885612487793 batch avg IoU tensor(0.5516, device='cuda:0')\n","304/316 batch loss 0.4609695374965668 batch avg IoU tensor(0.5425, device='cuda:0')\n","305/316 batch loss 0.44130614399909973 batch avg IoU tensor(0.5623, device='cuda:0')\n","306/316 batch loss 0.4073406457901001 batch avg IoU tensor(0.5950, device='cuda:0')\n","307/316 batch loss 0.424602746963501 batch avg IoU tensor(0.5785, device='cuda:0')\n","308/316 batch loss 0.44158774614334106 batch avg IoU tensor(0.5609, device='cuda:0')\n","309/316 batch loss 0.42682257294654846 batch avg IoU tensor(0.5749, device='cuda:0')\n","310/316 batch loss 0.4104869067668915 batch avg IoU tensor(0.5919, device='cuda:0')\n","311/316 batch loss 0.43741193413734436 batch avg IoU tensor(0.5641, device='cuda:0')\n","312/316 batch loss 0.4057351052761078 batch avg IoU tensor(0.5970, device='cuda:0')\n","313/316 batch loss 0.4548674523830414 batch avg IoU tensor(0.5483, device='cuda:0')\n","314/316 batch loss 0.43700525164604187 batch avg IoU tensor(0.5667, device='cuda:0')\n","315/316 batch loss 0.4132837951183319 batch avg IoU tensor(0.5895, device='cuda:0')\n","epoch  0 num batches 316  train loss: 0.43002370556321323\n","epoch  0 validation IoU tensor(0.5619, device='cuda:0')\n"]}],"source":["g = unet_train(rn, EPOCH)\n","un = g['model']"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-25T11:30:26.882913Z","iopub.status.busy":"2023-06-25T11:30:26.881962Z","iopub.status.idle":"2023-06-25T11:30:26.892555Z","shell.execute_reply":"2023-06-25T11:30:26.891626Z","shell.execute_reply.started":"2023-06-25T11:30:26.882875Z"},"trusted":true},"outputs":[{"data":{"text/plain":["UNet(\n","  (rene): myresnet(\n","    (backbone): ResNet(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (4): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (5): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","      (fc): Linear(in_features=512, out_features=1000, bias=True)\n","    )\n","    (classifier): Sequential(\n","      (fc1): Linear(in_features=512, out_features=512, bias=True)\n","      (relu): ReLU()\n","      (fc2): Linear(in_features=512, out_features=2, bias=True)\n","      (output): LogSoftmax(dim=1)\n","    )\n","  )\n","  (ct2d): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n","  (c2d): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU()\n","  (ct2d2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","  (c2d2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (ct2d3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","  (c2d3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (ct2d4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","  (c2d4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (ct2d5): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n","  (c2d5): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["un.eval()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":5}
